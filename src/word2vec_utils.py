import os
from pathlib import Path
from typing import List, Optional, Dict
from gensim.models import Word2Vec
from rich.console import Console
import numpy as np
from collections import Counter
from nltk.tokenize import sent_tokenize, word_tokenize
import nltk
import logging

# Download necess√°rio do NLTK
nltk.download('punkt')

console = Console()
logger = logging.getLogger(__name__)

class Word2VecUtils:
    def __init__(self, 
                 obsidian_vault: str = "F:/pasta estudos/Code Brain",
                 model_dir: str = "models/word2vec",
                 model_name: str = "model.bin",
                 vector_size: int = 100):
        # Configura caminhos
        self.vault_path = Path(obsidian_vault)
        self.transcricoes_path = self.vault_path / "Transcri√ß√µes"
        self.base_path = Path(__file__).parent.parent
        self.model_path = self.base_path / model_dir / model_name
        
        self.vector_size = vector_size
        self.model = None
        
        console.print(f"üìÇ Vault Obsidian: {self.vault_path}")
        console.print(f"üìÇ Pasta de Transcri√ß√µes: {self.transcricoes_path}")
        
        # For√ßa treinamento inicial
        self.train_initial_model()
        
    def prepare_sentences(self) -> List[List[str]]:
        """Prepara senten√ßas das transcri√ß√µes do Obsidian"""
        sentences = []
        
        if not self.transcricoes_path.exists():
            console.print("‚ùå Pasta de transcri√ß√µes n√£o encontrada!", style="red")
            return sentences
        
        # Lista todos os arquivos .md e .txt
        files = list(self.transcricoes_path.glob("*.md"))
        files.extend(self.transcricoes_path.glob("*.txt"))
        
        if not files:
            console.print("‚ùå Nenhuma transcri√ß√£o encontrada!", style="red")
            return sentences
        
        # Processa cada arquivo
        for file in files:
            console.print(f"üìÑ Processando: {file.name}")
            try:
                with open(file, "r", encoding="utf-8") as f:
                    text = f.read()
                    sentences.extend([sentence.split() for sentence in text.split("\n")])
            except Exception as e:
                console.print(f"‚ùå Erro ao ler {file.name}: {e}", style="red")
        
        return sentences

    def train_initial_model(self):
        """Treina o modelo inicial de Word2Vec"""
        sentences = self.prepare_sentences()
        if not sentences:
            console.print("‚ùå Nenhuma senten√ßa preparada para treinamento!", style="red")
            return
        
        try:
            self.model = Word2Vec(sentences=sentences, vector_size=self.vector_size, window=5, min_count=1, workers=4)
            self.model.save(self.model_path)
            console.print("‚úÖ Modelo Word2Vec treinado e salvo!", style="green")
        except Exception as e:
            console.print(f"‚ùå Erro ao treinar o modelo Word2Vec: {e}", style="red")

    def treinar_word2vec(self):
        """Treina o modelo Word2Vec e analisa as transcri√ß√µes."""
        console.print("\nüîç Analisando transcri√ß√µes...", style="blue")
        
        # Carregar as transcri√ß√µes
        transcricoes = []
        palavras_frequentes = Counter()
        temas = set()
        
        for arquivo in os.listdir(self.transcricoes_path):
            if arquivo.endswith(".txt"):
                try:
                    with open(os.path.join(self.transcricoes_path, arquivo), "r", encoding="utf-8") as f:
                        texto = f.read()
                        transcricoes.append(texto)
                        
                        # An√°lise do conte√∫do
                        palavras = texto.lower().split()
                        palavras_frequentes.update(palavras)
                        
                        # Identifica poss√≠veis temas
                        for palavra, freq in Counter(palavras).items():
                            if freq > 3 and len(palavra) > 3:  # Palavras significativas
                                temas.add(palavra)
                                
                    console.print(f"‚úÖ Analisado: {arquivo}", style="green")
                except Exception as e:
                    console.print(f"‚ùå Erro ao ler {arquivo}: {e}", style="red")

        # Tokenizar as transcri√ß√µes
        sentencas = []
        for transcricao in transcricoes:
            sentencas.extend([sentenca.split() for sentenca in transcricao.split("\n")])

        # Criar e treinar o modelo
        try:
            model = Word2Vec(
                sentences=sentencas, 
                vector_size=100, 
                window=5, 
                min_count=1, 
                workers=4
            )
            
            # Salvar o modelo
            model.save("word2vec.model")
            console.print("\n‚úÖ Modelo treinado e salvo!", style="green")
            
            # Mostrar an√°lise
            console.print("\nüìä An√°lise do Conte√∫do:", style="bold blue")
            
            # Palavras mais frequentes
            console.print("\nüî§ Palavras mais frequentes:", style="cyan")
            for palavra, freq in palavras_frequentes.most_common(20):
                if len(palavra) > 3:  # Ignorar palavras muito curtas
                    console.print(f"  ‚Ä¢ {palavra}: {freq}", style="green")
            
            # Temas identificados
            console.print("\nüè∑Ô∏è Poss√≠veis temas:", style="cyan")
            for tema in sorted(list(temas))[:15]:
                console.print(f"  ‚Ä¢ {tema}", style="green")
            
            # Exemplos de rela√ß√µes
            console.print("\nüîó Exemplos de palavras relacionadas:", style="cyan")
            for palavra in sorted(list(temas))[:5]:
                try:
                    similares = model.wv.most_similar(palavra)
                    console.print(f"\n  Relacionadas a '{palavra}':", style="yellow")
                    for similar, score in similares[:3]:
                        console.print(f"   - {similar}: {score:.2f}", style="green")
                except:
                    continue
                    
        except Exception as e:
            console.print(f"\n‚ùå Erro ao treinar modelo: {e}", style="red")
            return None
        
        return model

    def load_model(self) -> bool:
        """Carrega o modelo Word2Vec existente"""
        try:
            if self.model_path.exists():
                self.model = Word2Vec.load(str(self.model_path))
                console.print(f"‚úÖ Modelo carregado de: {self.model_path}", style="green")
                return True
            return False
        except Exception as e:
            console.print(f"‚ùå Erro ao carregar modelo: {e}", style="red")
            return False

    def obter_vetor_palavra(self, palavra):
        """Obt√©m o vetor de uma palavra usando o modelo Word2Vec."""
        model = Word2Vec.load("word2vec.model")
        return model.wv[palavra]

    def palavras_similares(self, palavra: str, n: int = 5) -> List[Dict[str, float]]:
        """
        Encontra palavras similares
        
        Args:
            palavra: Palavra de refer√™ncia
            n: N√∫mero de palavras similares
            
        Returns:
            Lista de dicion√°rios com palavras e scores
        """
        if self.model is None:
            if not self.load_model():
                return []
        
        try:
            similares = self.model.wv.most_similar(palavra.lower(), topn=n)
            return [{"palavra": p, "score": float(s)} for p, s in similares]
        except KeyError:
            return []

    def calcular_similaridade(self, palavra1: str, palavra2: str) -> Optional[float]:
        """
        Calcula similaridade entre duas palavras
        
        Args:
            palavra1: Primeira palavra
            palavra2: Segunda palavra
            
        Returns:
            Score de similaridade ou None se erro
        """
        if self.model is None:
            if not self.load_model():
                return None
        
        try:
            return float(self.model.wv.similarity(palavra1.lower(), palavra2.lower()))
        except KeyError:
            return None

    def existe_palavra(self, palavra: str) -> bool:
        """Verifica se uma palavra existe no vocabul√°rio"""
        if self.model is None:
            if not self.load_model():
                return False
        return palavra.lower() in self.model.wv

def preprocess_text(text: str) -> List[List[str]]:
    """
    Pr√©-processa o texto para treinamento do Word2Vec.
    
    Args:
        text: Texto para processar
        
    Returns:
        Lista de senten√ßas tokenizadas
    """
    try:
        # Divide em senten√ßas
        sentences = sent_tokenize(text.lower())
        
        # Tokeniza cada senten√ßa
        return [
            word_tokenize(sentence)
            for sentence in sentences
        ]
    except Exception as e:
        logger.error(f"Erro no pr√©-processamento: {e}")
        return []

def train_word2vec_model(
    texts: List[str],
    vector_size: int = 100,
    window: int = 5,
    min_count: int = 2,
    workers: int = 4,
    epochs: int = 10
) -> Word2Vec:
    """
    Treina um novo modelo Word2Vec.
    
    Args:
        texts: Lista de textos para treinamento
        vector_size: Dimens√£o dos vetores
        window: Tamanho da janela de contexto
        min_count: Frequ√™ncia m√≠nima das palavras
        workers: N√∫mero de threads
        epochs: N√∫mero de √©pocas de treinamento
        
    Returns:
        Modelo Word2Vec treinado
    """
    try:
        # Pr√©-processa todos os textos
        sentences = []
        for text in texts:
            sentences.extend(preprocess_text(text))
            
        if not sentences:
            raise ValueError("Nenhuma senten√ßa v√°lida para treinamento")
            
        # Treina o modelo
        model = Word2Vec(
            sentences=sentences,
            vector_size=vector_size,
            window=window,
            min_count=min_count,
            workers=workers,
            epochs=epochs
        )
        
        return model
        
    except Exception as e:
        logger.error(f"Erro no treinamento do modelo: {e}")
        raise

def load_word2vec_model(path: str) -> Word2Vec:
    """
    Carrega um modelo Word2Vec salvo.
    
    Args:
        path: Caminho do arquivo do modelo
        
    Returns:
        Modelo Word2Vec carregado
    """
    try:
        model = Word2Vec.load(path)
        return model
    except Exception as e:
        logger.error(f"Erro ao carregar modelo: {e}")
        raise

def update_word2vec_model(
    model: Word2Vec,
    new_texts: List[str],
    epochs: int = 1
) -> Word2Vec:
    """
    Atualiza um modelo existente com novos textos.
    
    Args:
        model: Modelo Word2Vec existente
        new_texts: Novos textos para treinamento
        epochs: N√∫mero de √©pocas para atualiza√ß√£o
        
    Returns:
        Modelo Word2Vec atualizado
    """
    try:
        # Pr√©-processa novos textos
        new_sentences = []
        for text in new_texts:
            new_sentences.extend(preprocess_text(text))
            
        if not new_sentences:
            return model
            
        # Atualiza o modelo
        model.build_vocab(new_sentences, update=True)
        model.train(
            new_sentences,
            total_examples=len(new_sentences),
            epochs=epochs
        )
        
        return model
        
    except Exception as e:
        logger.error(f"Erro na atualiza√ß√£o do modelo: {e}")
        raise

def main():
    """Testa a utilidade"""
    # Inicializa com o caminho do seu vault
    w2v = Word2VecUtils(obsidian_vault="F:/pasta estudos/Code Brain")
    
    # Palavras para testar
    test_words = [
        "python",
        "programa√ß√£o",
        "desenvolvimento",
        "web",
        "dados"
    ]
    
    # Testa cada palavra
    for palavra in test_words:
        console.print(f"\nüîç Testando: {palavra}")
        
        if w2v.existe_palavra(palavra):
            similares = w2v.palavras_similares(palavra)
            console.print("Palavras similares:", style="green")
            for similar in similares:
                console.print(f"  - {similar['palavra']}: {similar['score']:.4f}")
        else:
            console.print(f"‚ùå Palavra '{palavra}' n√£o encontrada", style="yellow")

if __name__ == "__main__":
    main()
    # Chama a fun√ß√£o para analisar o conte√∫do do vault